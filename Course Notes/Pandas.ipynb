{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pandas\n",
        "_Alistair Boyer_"
      ],
      "metadata": {
        "id": "279CXXWOOIwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "import numpy\n",
        "\n",
        "print(f'Pandas version: {pandas.__version__}')\n",
        "print(f'Numpy version: {numpy.__version__}')"
      ],
      "metadata": {
        "id": "HbK_zAqFzChV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87b7e139-c915-44fb-f85e-ee10a382ea78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pandas version: 1.5.3\n",
            "Numpy version: 1.25.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn\n",
        "df = seaborn.load_dataset(\"penguins\")"
      ],
      "metadata": {
        "id": "k7Yuq0nD7cA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating, Reading and Converting Data"
      ],
      "metadata": {
        "id": "CbbsR734yZ5G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating pandas objects\n",
        "```python\n",
        "pandas.Series(\n",
        "    [data_point, ...],         # from iterable\n",
        "    index=[index, ...],        # default is RangeIndex(0, 1, 2, ...)\n",
        "    name=name,\n",
        "    dtype=dtype,               # default is to infer\n",
        ")  # -> Series\n",
        "pandas.Series(\n",
        "    {index: data_point, ...},  # from dict\n",
        "    ...\n",
        ")  # -> Series\n",
        "\n",
        "pandas.DataFrame(\n",
        "    {column_label: series_data, ...}  # from dict\n",
        ")  # -> DataFrame\n",
        "pandas.DataFrame(\n",
        "    zip(series_data, ...),            # from iterables\n",
        "    columns=[column_label, ...],\n",
        ")  # -> DataFrame\n",
        "\n",
        "series.to_frame(column_label)  # -> DataFrame\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "fGS6896pyqt0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "copy\n",
        "```python\n",
        "DataFrame.copy()  # -> DataFrame\n",
        "Series.copy()  # -> Series\n",
        "```"
      ],
      "metadata": {
        "id": "uCQnzbe3AOEq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "reading data\n",
        "```python\n",
        "pandas.read_csv(\n",
        "    {path | url | stream},\n",
        "    encoding='utf-8',\n",
        "    sep=',',                  # \\t for tab\n",
        "    header={1 | None | int},  # location of header row\n",
        "    names=column_names,       # if header is None\n",
        "    index_col={0 | name},\n",
        ")  # -> DataFrame\n",
        "\n",
        "# chunks as a stream\n",
        "chunks = pandas.read_csv(\n",
        "    src,\n",
        "    chunksize=n,\n",
        "    ...,\n",
        ")  # -> DataFrame\n",
        "\n",
        "# concat chunks\n",
        "pandas.concat(chunks)  # -> DataFrame\n",
        "```"
      ],
      "metadata": {
        "id": "c6RGIRqgCN_k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "read and conversion methods"
      ],
      "metadata": {
        "id": "hYIBuMKDDsLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read methods\n",
        "print([f for f in dir(pandas) if f.startswith('read_')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4f_iv87y1Tc",
        "outputId": "e5df7e91-b83b-4ac2-dfde-d94038c9926c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['read_clipboard', 'read_csv', 'read_excel', 'read_feather', 'read_fwf', 'read_gbq', 'read_hdf', 'read_html', 'read_json', 'read_orc', 'read_parquet', 'read_pickle', 'read_sas', 'read_spss', 'read_sql', 'read_sql_query', 'read_sql_table', 'read_stata', 'read_table', 'read_xml']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DataFrame ouptut methods\n",
        "print([f for f in dir(pandas.DataFrame) if f.startswith('to_')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGdGoSmc0NrS",
        "outputId": "18590904-7c12-477b-e5e8-b0d79c64c47b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['to_clipboard', 'to_csv', 'to_dict', 'to_excel', 'to_feather', 'to_gbq', 'to_hdf', 'to_html', 'to_json', 'to_latex', 'to_markdown', 'to_numpy', 'to_orc', 'to_parquet', 'to_period', 'to_pickle', 'to_records', 'to_sql', 'to_stata', 'to_string', 'to_timestamp', 'to_xarray', 'to_xml']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Series ouptut methods\n",
        "print([f for f in dir(pandas.Series) if f.startswith('to_')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQBtCd890W-R",
        "outputId": "8e699a5e-cddd-4b7a-a572-9cb9e838da6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['to_clipboard', 'to_csv', 'to_dict', 'to_excel', 'to_frame', 'to_hdf', 'to_json', 'to_latex', 'to_list', 'to_markdown', 'to_numpy', 'to_period', 'to_pickle', 'to_sql', 'to_string', 'to_timestamp', 'to_xarray']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Information about the Dataset"
      ],
      "metadata": {
        "id": "Ae6stVgjoBh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "shape and size\n",
        "```python\n",
        "DataFrame.shape    # READONLY -> Tuple[int, int]\n",
        "Series.shape       # READONLY -> Tuple[int]\n",
        "\n",
        "DataFrame.size     # READONLY -> int, equivalent to DataFrame.shape[0] * DataFrame.shape[1]\n",
        "```"
      ],
      "metadata": {
        "id": "j7v9n7SIGG8L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "indexes\n",
        "```python\n",
        "DataFrame.columns  # -> Index\n",
        "DataFrame.keys()   # -> Index, equivalent to DataFrame.columns\n",
        "\n",
        "DataFrame.index    # -> Index\n",
        "Series.index       # -> Index\n",
        "Series.keys()      # -> Index, equivalent to DataFrame.index\n",
        "```"
      ],
      "metadata": {
        "id": "3mAqEgQVHwun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "counts\n",
        "```python\n",
        "len(DataFrame | Series)        # -> int\n",
        "DataFrame.count()              # -> int, equivalent to len(DataFrame)\n",
        "Series.count()                 # -> int, equivalent to len(Series)\n",
        "\n",
        "DataFrame.nunique()            # -> Series of counts\n",
        "Series.nunique()               # -> int\n",
        "\n",
        "DataFrame.value_counts(\n",
        "    normalize={False | True},  # scale so all add up to 1.0\n",
        ")  # -> Series, multiindex = column labels, values = (normalised) count descending\n",
        "Series.value_counts(...)\n",
        "```"
      ],
      "metadata": {
        "id": "-A22is4YSqxr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "informaton about nulls\n",
        "```python\n",
        "DataFrame.info(\n",
        "    verbose={True | False},\n",
        ")  # -> None\n",
        "Series.info(...)  # -> None\n",
        "# print VALUES and RETURN None\n",
        "\n",
        "Series.hasnans  # -> bool\n",
        "\n",
        "DataFrame.isnull().sum()\n",
        "Series.isnull().sum()\n",
        "```"
      ],
      "metadata": {
        "id": "afEJPOVurMXR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "unique values\n",
        "```python\n",
        "Series.unique()  # -> ndarray, alisas of numpy.unique(Series)\n",
        "set(Series)      # -> set\n",
        "```"
      ],
      "metadata": {
        "id": "GWDCsWFg81c3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accessing Data by Index"
      ],
      "metadata": {
        "id": "Q49-vY1ZoCNb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "head and tail\n",
        "```python\n",
        "DataFrame.head(n=5)  # -> DataFrame, equivalent to DataFrame.iloc[:n] including -ve\n",
        "Series.head(n=5)     # -> Series, equivalent to Series.iloc[:n] including -ve\n",
        "```\n",
        "```python\n",
        "DataFrame.tail(n=5)  # -> DataFrame, equivalent to DataFrame.iloc[-n:] including -ve\n",
        "Series.tail(n=5)     # -> Series, equivalent to Series.iloc[-n:] including -ve\n",
        "```"
      ],
      "metadata": {
        "id": "PgI0o5falS0M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "all content\n",
        "```python\n",
        "DataFrame.values        # -> ndarray\n",
        "Series.values           # -> ndarray\n",
        "\n",
        "DataFrame.items()       # -> Generator of column Series\n",
        "DataFrame.iterrows()    # -> Generator of row Series\n",
        "DataFrame.itertuples()  # -> Generator of NamedTuples for each row\n",
        "\n",
        "Series.items()          # -> Generator of Tuples (index, value)\n",
        "```"
      ],
      "metadata": {
        "id": "BwLdIWgZPRTV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "indexing using [&nbsp;] and . {`__getitem__`, `__getattribute__`}\n",
        "```python\n",
        "DataFrame[column_label]         # -> Series, alias of DataFrame.loc[:, column_label]\n",
        "DataFrame.column_label          # -> Series, alias of DataFrame.loc[:, column_label]\n",
        "DataFrame[[column_label, ...]]  # -> DataFrame of selected columns, alias of DataFrame.loc[:, [column_label, ...]]\n",
        "\n",
        "DataFrame[start:stop:step]      # -> DataFrame of sliced rows, alias of DataFrame.loc[row_index_slice, :]\n",
        "\n",
        "Series[row_label]               # -> value, alias of Series.loc['row_label']\n",
        "\n",
        "# Bonus:\n",
        "#DataFrame.get(column_labels, default)\n",
        "#DataFrame.pop()\n",
        "```"
      ],
      "metadata": {
        "id": "SmTe9HrWw2uk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "loc - label indexing (inclusive ranges)\n",
        "```python\n",
        "# label indexing\n",
        "DataFrame.loc[row_label(s), column_label(s)]         # -> DataFrame\n",
        "Series.loc[row_label(s)]                             # -> value\n",
        "\n",
        "# slice indexing\n",
        "DataFrame.loc[row_label_slice, column_label_slice]   # -> DataFrame\n",
        "Series.loc[row_label_slice]                          # -> Series\n",
        "\n",
        "# mask indexing\n",
        "DataFrame.loc[row_bool_mask, column_bool_mask]       # -> DataFrame\n",
        "Series.loc[row_bool_mask]                            # -> Series\n",
        "\n",
        "# can mix methods of .loc indexing\n",
        "```"
      ],
      "metadata": {
        "id": "yX1wzNkos8x1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "iloc - integer indexing (exclusive ranges)\n",
        "```python\n",
        "# value indexing\n",
        "DataFrame.iloc[row_index(es), column_index(es)]      # -> DataFrame\n",
        "Series.iloc[row_index]                               # -> Series\n",
        "\n",
        "# slice indexing\n",
        "DataFrame.iloc[row_index_slice, column_index_slice]  # -> DataFrame\n",
        "Series.iloc[row_index_slice]                         # -> Series\n",
        "\n",
        "# can mix methods of .iloc indexing\n",
        "```"
      ],
      "metadata": {
        "id": "auIocTmcODOA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "slicing\n",
        "```python\n",
        "slice(\n",
        "    start=None,\n",
        "    stop,      # if a single value is passed as *arg then it is considered as stop\n",
        "    step=None,\n",
        ")\n",
        "\n",
        "[start:stop:step] === slice(start, stop, step)\n",
        "[start:stop] === slice(start, stop, None)\n",
        "[::step] === slice(None, None, step)\n",
        "\n",
        ": === slice(None) === slice(None, None, None)\n",
        "... === fill other axes with ':'\n",
        "\n",
        "[val] == [slice(val, val+1, None)][0]\n",
        "```"
      ],
      "metadata": {
        "id": "7owNeZUYyKII"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accessing Data with Tools"
      ],
      "metadata": {
        "id": "NDbr_YXdPNCq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "filtering\n",
        "```python\n",
        "DataFrame.filter(         # filter by index\n",
        "    items=[labels, ],     # supply items= OR like= OR regex=\n",
        "    like='substring',\n",
        "    regex=rexpression',\n",
        "    axis={1 | 0},\n",
        ")  # -> DataFame\n",
        "\n",
        "DataFrame.select_dtypes(           # filter columns by data type\n",
        "    include={None | [datatype, ...]},\n",
        "    exclude={None | [datatype, ...]},\n",
        ")  # -> DataFrame\n",
        "```"
      ],
      "metadata": {
        "id": "3W-mudbv6htf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "where\n",
        "```python\n",
        "DataFrame.where(\n",
        "    condition,\n",
        "    value_if_false\n",
        ")\n",
        "\n",
        "# see also:\n",
        "numpy.where(\n",
        "    condition,\n",
        "    value_if_true,\n",
        "    value_if_false,\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "Q8TIBnN3PB3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "random sampling\n",
        "```python\n",
        "DataFrame.sample(\n",
        "    n=n,                     # number of samples\n",
        "    replace={False | True},  # allow duplicates\n",
        ")  # -> DataFrame\n",
        "\n",
        "Series.sample(...)  # -> Series\n",
        "```"
      ],
      "metadata": {
        "id": "mh1oI22AKb4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "query\n",
        "```python\n",
        "DataFrame.query(\n",
        "    \"col1 + col2 ** 2\",      # text query\n",
        "    inplace={False | True},\n",
        "    **kwargs,                # for any operation within the query\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "GCb5Ug_ptQbG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Index"
      ],
      "metadata": {
        "id": "waHTjr807Mn0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "DataFrame.set_index(\n",
        "    label,                   # column to set as index\n",
        "    inplace={False | True},\n",
        ")\n",
        "\n",
        "DataFrame.reset_index(\n",
        "    drop={False | True},     # delete index or move to standard column\n",
        "    inplace={False | True},\n",
        ")\n",
        "Series.reset_index(...)  # -> DataFrame\n",
        "\n",
        "# manual column ordering\n",
        "DataFrame.reindex(\n",
        "    columns=desired_order_of_column_labels,\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "3LJ8o1WH7PqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Types"
      ],
      "metadata": {
        "id": "9hSDjl4u-NfO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "dtype\n",
        "```python\n",
        "DataFrame.dtypes   # READONLY -> Series of column dtype\n",
        "Series.dtype       # READONLY -> dtype\n",
        "```"
      ],
      "metadata": {
        "id": "iQHj7FJcGJYA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "astype\n",
        "```python\n",
        "Series.astype(\n",
        "    int, str, float, 'int', 'uint32', 'category', ...\n",
        ")\n",
        "\n",
        "DataFrame.astype(\n",
        "    {colname: type, }\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "FcU9jWkhGegv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Joining and Adding Data"
      ],
      "metadata": {
        "id": "VCuD4VzCXYNp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "join\n",
        "```python\n",
        "# N.B. index must be the same\n",
        "DataFrame.join(\n",
        "    {DataFrame | Series | Collection},\n",
        "    r_suffix=r_suffix,                  # labels for overlapping column labels\n",
        ")  # -> DataFrame\n",
        "```"
      ],
      "metadata": {
        "id": "rfyIf4vSXgnu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "merge\n",
        "```python\n",
        "DataFrame.merge(\n",
        "    other_data,\n",
        "    how={'left' | 'inner' | ...,},\n",
        "    on=column_label,\n",
        "    left_on=column_label,\n",
        "    right_on=column_label,\n",
        "    suffixes=('_x', '_y'),    \n",
        ")  # -> DataFrame\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "qMRgwIJI8w8u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "concat\n",
        "```python\n",
        "pandas.concat(\n",
        "    (DataFrames, Series, ...),  # collection of data sources\n",
        "    axis={0 | 1},               # 0: add to rows, 1: add to columns\n",
        ")  # -> DataFrame\n",
        "```"
      ],
      "metadata": {
        "id": "bgiZ4xR_Xj3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "insert\n",
        "```python\n",
        "DataFrame.insert(\n",
        "    loc=iloc,\n",
        "    column=column_label,\n",
        "    value=data,\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "68mnAeiqaBTj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explode"
      ],
      "metadata": {
        "id": "fgO-B4mxCZ9r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert list-like data to separate __rows__ with __repeated__ index\n",
        "```python\n",
        "DataFrame.explode(\n",
        "    column=label,\n",
        ")  # -> DataFrame\n",
        "\n",
        "Series.explode(\n",
        ")  # -> Series\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "c4itG1lnoVaA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nulls"
      ],
      "metadata": {
        "id": "N2OvGefEFNA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "null filters\n",
        "```python\n",
        "DataFrame.isnull()   # -> DataFrame of bools, equivalent to DataFrame.isna()\n",
        "DataFrame.notnull()  # -> DataFrame of bools, equivalent to DataFrame.notna()\n",
        "\n",
        "Series.isnull()      # -> Series of bools, equivalent to Series.isna()\n",
        "Series.notnull()     # -> Series of bools, equivalent to Series.notna()\n",
        "```"
      ],
      "metadata": {
        "id": "BJBT8xvOzpXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "dropping nulls\n",
        "```python\n",
        "DataFrame.dropna(\n",
        "    axis=0,                      # along rows\n",
        "    subset=[column_label, ...],  # columns to consider\n",
        "    how={'any' | 'all'},         # drop if one or all null\n",
        "    inplace={False | True}\n",
        ")  # -> DataFrame (or None if inplace)\n",
        "```"
      ],
      "metadata": {
        "id": "qT9pyzWd0d-o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "filling nulls\n",
        "```python\n",
        "DataFrame.fillna(\n",
        "    value={value | dict | Series | Dataframe},  # new value\n",
        "    inplace={False | True}\n",
        ")  # -> DataFrame (or None if inplace)\n",
        "\n",
        "# see also:\n",
        "DataFrame.bfill()\n",
        "DataFrame.ffill()\n",
        "```"
      ],
      "metadata": {
        "id": "PySsaip_Y1tg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "null friendly methods\n",
        "```python\n",
        "DataFrame.radd, .rsub, .rmul, .rdiv, .rfloordiv, .rmod, .rpow\n",
        "# equivalent to add, etc. but with the option to supply a value to use in case of null\n",
        "```"
      ],
      "metadata": {
        "id": "2SqnrCknFQqb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deleting and Renaming"
      ],
      "metadata": {
        "id": "tZECCbjwyRMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "dropping\n",
        "```python\n",
        "DataFrame.drop(\n",
        "    labels=[column_label, ...],\n",
        "    axis={0 | 1},                  # 0 = rows (default), 1 = cols\n",
        "    inplace={False | True},\n",
        ")\n",
        "\n",
        "Series.drop(\n",
        "    labels=[row_label, ...],\n",
        "    inplace={False | True},\n",
        ")\n",
        "\n",
        "# see also DataFrame.pop()\n",
        "```"
      ],
      "metadata": {
        "id": "OAReQTnJyTju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "dropping duplicates\n",
        "```python\n",
        "DataFrame.drop_duplicates(\n",
        "    subset=[column_label, ...],\n",
        "    keep={'first' | 'last' | False}   # False DROPS ALL duplicates\n",
        "    inplace={False | True},\n",
        ")\n",
        "\n",
        "Series.drop_duplicates(\n",
        "    ...\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "wUNnxT425gwN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "renaming\n",
        "```python\n",
        "DataFrame.rename (\n",
        "    columns={from: to},\n",
        "    inplace={False | True},\n",
        ")\n",
        "\n",
        "DataFrame.columns = new_column_labels\n",
        "Series.name = new_series_label\n",
        "\n",
        "DataFrame.index = new_index\n",
        "Series.index = new_index\n",
        "```"
      ],
      "metadata": {
        "id": "UmgYO8gr6IaC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sorting"
      ],
      "metadata": {
        "id": "0ijXPiX39vcY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "sorting values\n",
        "```python\n",
        "DataFrame.sort_values(\n",
        "    [column_labels, ...],             # or single value\n",
        "    ascending=[{True | False}, ...],  # or single value\n",
        "    inplace={False | True},\n",
        ")\n",
        "\n",
        "Series.sort_values(...)\n",
        "```\n",
        "\n",
        "sorting index\n",
        "```python\n",
        "DataFrame.sort_index(\n",
        "    inplace={False | True},\n",
        ")\n",
        "Series.sort_index(...)\n",
        "```"
      ],
      "metadata": {
        "id": "uJJ6Tblt9ZVJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "rank\n",
        "```python\n",
        "Series.rank(\n",
        "    method={'average' | 'min' | 'max' | 'first' | 'dense'},  # how to rank groups with same value\n",
        "    na_option={'keep' | 'top' | 'bottom'},                   # what to do with nulls\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "eHynrK78-02Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis"
      ],
      "metadata": {
        "id": "ij3vu9-zOukx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overview Statistics\n",
        "```python\n",
        "DataFrame.describe(\n",
        "    include={None | \"all\" | [dtype, ...]},\n",
        "    exclude={None | [dtype, ...]},\n",
        "    percentiles=[0.25, 0.5, 0.75],\n",
        ")  # -> DataFrame[index=agg_name, columns=columns]\n",
        "Series.describe(...)  # -> Series[index=agg_name, columns=columns]\n",
        "\n",
        "# EXCLUDES NULL VALUES\n",
        "# Default information: 'count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'\n",
        "# include='all' adds: 'unique', 'top', 'freq'\n",
        "```"
      ],
      "metadata": {
        "id": "UC8zL4k2ovyG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation\n",
        "```python\n",
        "DataFrame.corr(\n",
        "    method={\"pearson\" | \"kendall\" | \"spearman\" | Callable},\n",
        "    numeric_only={False | True},\n",
        ")  # -> DataFrame, cross-tabulated correlation (1.0 along diagonal)\n",
        "```"
      ],
      "metadata": {
        "id": "ajGf9Lj7OwW8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variance and Covariance\n",
        "```python\n",
        "DataFrame.var(\n",
        "    numeric_only={False | True},\n",
        ")  # -> Series, index = column names; values = variance\n",
        "\n",
        "DataFrame.cov(\n",
        "    numeric_only={False | True},\n",
        ")  # -> DataFrame, cross-tabulated covariance (variance along diagonal)\n",
        "```"
      ],
      "metadata": {
        "id": "NUGry0HVvPpI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binning"
      ],
      "metadata": {
        "id": "X1ApOsffAU_F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "binning based on ranges\n",
        "```python\n",
        "pandas.cut(\n",
        "    Series,\n",
        "    bins={n | [bin_edge, ...]},     # [n+1 bin edges] or int number of bins\n",
        "    labels=[label, ...],            # bin labels or 0, 1, 2...\n",
        "    include_lowest={False | True},  # set to True if using generated bin values!\n",
        "    retbins={False | True},         # function returns (DataFrame, bin_edges) if True\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "zGfbzUwIFN6f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "binning based on quantiles\n",
        "```python\n",
        "pandas.qcut(\n",
        "    Series,\n",
        "    q=number_of_quantiles  # number of quantiles (4 = quartile) or list of quartile edges\n",
        "    labels=[label, ...],\n",
        ")\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "sWNcLznnhUgT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying Functions Across Data"
      ],
      "metadata": {
        "id": "KXKVyQeMFQlu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "transform\n",
        "- must return data with same shape as original\n",
        "\n",
        "```python\n",
        "DataFrame.transform(               \n",
        "    func={\n",
        "      function(Series) -> Series     # function(s) to transform the data\n",
        "      | \"function_name\"\n",
        "      | {column: function, ...}\n",
        "    },\n",
        "    axis={0 | 1},                    # column = f(column), when axis = 0; row = f(row), when axis = 1\n",
        "    args, **kwargs,                  # passed to function\n",
        ")  # -> DataFrame\n",
        "\n",
        "\n",
        "Series.transform(...)                # as above, but axis must be 0\n",
        "```"
      ],
      "metadata": {
        "id": "a1iT2rqXq-pF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "apply\n",
        "  - similar to transform but no restrictions on shape of data returned\n",
        "\n",
        "```python\n",
        "DataFrame.apply(               \n",
        "    {\n",
        "      function(Series) -> Series    # function to transform the data\n",
        "      | \"function_name\"             # name of a Callable\n",
        "      | {column: function, ...}\n",
        "    },\n",
        "    axis={0 | 1},                   # column = f(column), when axis = 0; row = f(row), when axis = 1\n",
        "    raw={False | True},             # True => Series, False => numpy.array\n",
        "    args, **kwargs,                 # passed to function\n",
        ")  # -> DataFrame\n",
        "\n",
        "Series.apply(\n",
        "    {\n",
        "      function(Series) -> Series    # function(s) to transform the data\n",
        "      | \"function_name\"\n",
        "    },\n",
        "    args, **kwargs,                 # passed to function\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "0W08tPZk-8QE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "map and replace\n",
        "  -  convert values in Series according to supplied dict (or function)\n",
        "\n",
        "```python\n",
        "Series.map(\n",
        "    {\n",
        "        {from: to,}               # conversion of values\n",
        "        |  function\n",
        "        |  Series\n",
        "    },\n",
        "    na_action={None | 'ignore'},  # how to behave with null values\n",
        ")  # -> Series\n",
        "\n",
        "Series.replace(\n",
        "    current_values,               # can be numeric, str, regex or list\n",
        "    replacemant_values,           # can also be dict as for map\n",
        "    regex={False | True},\n",
        ")  # -> Series\n",
        "# see also Series.str.replace()\n",
        "```"
      ],
      "metadata": {
        "id": "iZ4xzR3N4ZWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "applymap\n",
        " - apply function to every value in DataFrame\n",
        " - renamed as _DataFrame_._map_ for version 2.1.0+\n",
        "\n",
        "```python\n",
        "DataFrame.applymap(            \n",
        "    lambda value: f(value),    # for every value: value = f(value)\n",
        ")                              # -> DataFrame\n",
        "```"
      ],
      "metadata": {
        "id": "yjJwfzjrsnBC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pivot and Crosstab"
      ],
      "metadata": {
        "id": "hRH6I7-Liq_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "crosstab\n",
        " - does not need to be a dataframe\n",
        " - defaults to \"count\" (no value required)\n",
        " - can be used for other agregations with value supplied\n",
        "\n",
        "```python\n",
        "pandas.crosstab(\n",
        "    index=Series,              # rows\n",
        "    columns=Series,            # columns\n",
        "    values={None | Series},    # None or values for aggfunc\n",
        "    aggfunc={None | aggfunc},  # counts values if None, else aggfunc of values\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "LSZyoaqI_Tg0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pivot table\n",
        " - needs to be a dataframe\n",
        " - requires values and aggfunc\n",
        " - can use dummy value to access count\n",
        "\n",
        "```python\n",
        "DataFrame.pivot_table(\n",
        "    values={None | Series},                     # None or values for aggfunc\n",
        "    index=Series,                             # rows\n",
        "    columns=Series,                           # columns\n",
        "    aggfunc={\"mean\" | aggfunc |[aggfunc, ...]},  # aggfunc, or supply list of aggfuncs to split table\n",
        ") # -> DataFrame\n",
        "\n",
        "# also available using:\n",
        "pandas.pivot_table(\n",
        "    dataframe,\n",
        "    ... # as above\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "QN7CL7X2jJns"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggregation Methods"
      ],
      "metadata": {
        "id": "hBHB3EwS9hZz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        ".min()                        # minimum\n",
        ".max()                        # maximum\n",
        ".mean()                       # mean\n",
        ".median()                     # median\n",
        ".count()                      # count\n",
        ".sum()                        # sum\n",
        ".std()                        # standard deviation\n",
        ".var()                        # variance\n",
        ".prod()                       # product\n",
        ".mad()                        # mean absolute deviation [DEPRACATED]\n",
        "\n",
        ".agg(\n",
        "  {\n",
        "    'function_name',          # apply a named function to the data\n",
        "    | ['function_name', ...]  # apply multiple named functions to the data\n",
        "    | {'label': 'function'}   # specify which function(s) to apply to columns\n",
        "  }\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "vQPC1eVS683I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "index of extremes\n",
        "```python\n",
        "DataFrame.idxmax()          # index of maximum\n",
        "Series.idxmax()             # index of maximum\n",
        "DataFrame.idxmin()          # index of minimum\n",
        "Series.idxmin()             # index of minimum\n",
        "# example\n",
        "dataframe.iloc[dataframe[\"label\"].idxmax()]\n",
        "dataframe.iloc[dataframe[\"label\"]==dataframe[\"label\"].max()]\n",
        "```"
      ],
      "metadata": {
        "id": "bBwjTk8Rz7ue"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grouping Data"
      ],
      "metadata": {
        "id": "VB_O-nlU8ebw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "groupby\n",
        "```python\n",
        "DataFrame.groupby(\n",
        "    by={\n",
        "      [column_label, ...]       # ONLY by OR level\n",
        "      | {label: new_label}\n",
        "      | Callable[label]\n",
        "    },\n",
        "    level=level,                # for multiindex\n",
        "    sort={True | False},\n",
        "    group_keys={True | False},\n",
        "    dropna={True | False},\n",
        ")  # -> DataFrameGroupBy object\n",
        "```\n"
      ],
      "metadata": {
        "id": "WkUA3wfG2-PL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "methods for grouped data\n",
        "```python\n",
        "# general methods work on group data\n",
        "# the method is applied to each of the groups as if a DataFrame\n",
        "DataFrameGroupBy.head(n)                 \n",
        "DataFrameGroupBy.mean(numeric_only=True)\n",
        "DataFrameGroupBy.agg(['max', 'min', 'mean', ...])\n",
        "...\n",
        "```"
      ],
      "metadata": {
        "id": "-JlyZDg58159"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GroupBy.apply\n",
        "```python\n",
        "# apply function to each of the grouped DataFrames\n",
        "DataFrame.groupby(column_labels).apply(\n",
        "    lambda DataFrame: f(DataFrame),\n",
        ")\n",
        "\n",
        "# apply function to the Series within each of the groups\n",
        "Series.groupby(column_labels).apply(\n",
        "    lambda Series: f(Series),\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "jTKLXYMmsVBI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GroupBy.transform\n",
        "```python\n",
        "# use function to transform the columns within each of the grouped dataframes\n",
        "DataFrame.groupby(column_labels).transform(\n",
        "    lambda Series: f(Series),\n",
        ")\n",
        "\n",
        "# use a function to transform the Series within each of the groups\n",
        "# must return series of same shape as original\n",
        "Series.groupby(column_labels).transform(\n",
        "    lambda Series: f(Series),\n",
        ")\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "ueyR8n5ewimU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Window Functions and Shifting"
      ],
      "metadata": {
        "id": "MklS444gGKtv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "rolling\n",
        "```python\n",
        "DataFrame.rolling(\n",
        "    n,                    # number of rows to group together\n",
        "    centre={False|True},  # roll to bottom (False) or center (True)\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "kLHAQpXMF3Zr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "relative calculations\n",
        "```python\n",
        "# shift data by n rows in current order\n",
        "DataFrame.shift(n)\n",
        "\n",
        "# equivalent to\n",
        "shifted = dataframe.iloc[:-2]  # clip data\n",
        "shifted.index = dataframe.index[2:]  # shift index\n",
        "dataframe.index.to_frame().join(shifted).drop(columns=[0]) # get the null data back from the origingal index\n",
        "```"
      ],
      "metadata": {
        "id": "l-KfvWB1G6EH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "# percentange change\n",
        "Series.pct_change(n)\n",
        "# equivalent to\n",
        "Series/Series.shift(n) - 1\n",
        "\n",
        "# subtract\n",
        "DataFrame.diff(n)\n",
        "# equivalent to\n",
        "Series - Series.shift(n)\n",
        "```"
      ],
      "metadata": {
        "id": "Onk-QAjyGoxu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Category [.cat]\n",
        "```python\n",
        "# convert series to categorical (or nan)\n",
        "category = pd.Categorical(\n",
        "    [value, ...],          \n",
        "    categories=[category,...],  # default is to generate from .unique()\n",
        "    ordered={False | True},\n",
        ")  # -> Categorical\n",
        "\n",
        "Series.cat.add_categories(\n",
        "  [category, ...],\n",
        ")  # -> Categorical\n",
        "```"
      ],
      "metadata": {
        "id": "NISOWdzUaE3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## String [.str]"
      ],
      "metadata": {
        "id": "ObnDnmLDzZ2v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "# N.B. applying with .str will skip null values instead of raising an error\n",
        "Series.str\n",
        " []                                          # slicing\n",
        " .slice(start, stop, step)                   # .str[slice]\n",
        " .len()                                      # length\n",
        "\n",
        " .cat(series or str_to_join)                 # concatenate\n",
        "\n",
        " .capitalize()                               # First letter is capital\n",
        " .casefold()                                 # lower (for case insensitive matching)\n",
        " .lower()                                    # convert to lower case\n",
        " .swapcase()                                 # sWAP cASE\n",
        " .title()                                    # Convert To Title Case\n",
        " .upper()                                    # CONVERT TO UPPER CASE\n",
        "\n",
        " .isalpha()                                  # str is alphabetical\n",
        " .is...                                      # other str.is... methods\n",
        "\n",
        " .strip(chars)                               # remove chars from ends of str\n",
        " .rstrip(chars)                              # remove chars from ends of str\n",
        " .lstrip(chars)                              # remove chars from ends of str\n",
        "\n",
        " .contains(searchstr, regex={True | False})  # search (regex accepted)\n",
        " .count(searchstr, regex={True | False})     # count values in a str\n",
        " .extract(re, regex={True | False})          # extract match from str\n",
        " .replace(old, new, regex={True | False})    # replace\n",
        " .split(\n",
        "    split=split,\n",
        "    regex={True | False},\n",
        "    expand={False | True},                   # split a string (and expand to new cols)\n",
        " )\n",
        " .get(n)                                     # get nth value after split\n",
        "\n",
        " .get_dummies()                              # one hot encoding for categories\n",
        "\n",
        "\n",
        "\n",
        ".str.findall('\\w+').apply(''.join)           # remove word breaks\n",
        "```"
      ],
      "metadata": {
        "id": "3btgDqqxzb0q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datetime [.dt]"
      ],
      "metadata": {
        "id": "zaIguHZdDt5x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ".dt\n",
        "```python\n",
        "Series.dt\n",
        "  .hour\n",
        "  .year\n",
        "  .quarter\n",
        "  ...\n",
        "```"
      ],
      "metadata": {
        "id": "B_Sn-8pcHcfe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "creation\n",
        "```python\n",
        "pandas.to_datetime(\n",
        "    data,                # data for conversion, e.g. string\n",
        "    format='%Y-%m-%d',   # dat format (omit for automatic!)\n",
        ")\n",
        "\n",
        "# useful to set as index then sort\n",
        "dataframe.set_index('date_series', inplace=True)\n",
        "dataframe.sort_index(inplace=True)\n",
        "```"
      ],
      "metadata": {
        "id": "n_KkVQV2E6JU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "resample\n",
        "```python\n",
        "DataFrame.resample(\n",
        "    '1hour',         # time window to up/down sample to\n",
        ")\n",
        "# use with .bfill() and .ffill() when upsampling\n",
        "```"
      ],
      "metadata": {
        "id": "a0NiP2_8GPUZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "datetime range\n",
        "```python\n",
        "pandas.date_range(\n",
        "    start,            # start\n",
        "    periods=n,        # number of datapoints\n",
        "    freq=\"D\",         # days\n",
        ")\n",
        "\n",
        "# alternatively:\n",
        "pandas.date_range(start, end)  #  inclusive date range\n",
        "```\n",
        "\n",
        "business datetime range\n",
        "```python\n",
        "pandas.bdate_range(\n",
        "    start,\n",
        "    end,\n",
        "    freq='C',                   # 'C' = custom, default is 'B' = business daily\n",
        "    holidays=[date, ...],       # list of holidays, see numpy.busdaycalendar\n",
        "    weekmask=\"Mon Tue Thu Fri\"  # str of business days, see numpy.busdaycalendar\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "c1a_GW92HBDf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "timedelta\n",
        "```python\n",
        "pandas.timedelta(\"7 days\")  # other examples \"1 years\"\n",
        "# see datetime.timedelta(weeks=1)\n",
        "\n",
        "# can be used for arithmetic operations on datetime series\n",
        "# is the result of arithmetic operations on datetime series\n",
        "```"
      ],
      "metadata": {
        "id": "OZVvY_8QIbnu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Formatting DataFrames\n",
        "```python\n",
        "DataFrame.style.format(\n",
        "    formatter='{:0.2f}',  # supply a single value to format all or dict to format by column\n",
        ")  # -> Styler (can get data back with .data)\n",
        "```\n",
        "\n",
        "[Formatting for strings](https://docs.python.org/3/tutorial/inputoutput.html#formatted-string-literals)"
      ],
      "metadata": {
        "id": "o7V-bu1S7hF5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pandas Options"
      ],
      "metadata": {
        "id": "2uT9DnulXIcQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "pd.options.display.max_columns = {20 | None}  # How many columns to display n or all (None)\n",
        "pd.options.display.max_rows = {20 | None}     # How many rows to display n or all (None)\n",
        "```\n",
        "https://pandas.pydata.org/docs/user_guide/options.html"
      ],
      "metadata": {
        "id": "fmI-VVK8EDr7"
      }
    }
  ]
}